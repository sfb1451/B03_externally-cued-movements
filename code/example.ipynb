{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Externally-Cued Movements dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data access\n",
    "\n",
    "This notebook demos selected content and datatypes of this dataset. Data are available in the form of a\n",
    "[DataLad](https://datalad.org) dataset. This is a portable, versioned representation of the data that provides access to data and metadata. To learn more about working with DataLad datasets, visit the [DataLad handbook](https://handbook.datalad.org).\n",
    "\n",
    "The next cell obtains the dataset, and downloads the subset of the contained data relevant for the demos shown on this page. However, the dataset links all data, and additional downloads can be made, following the same approach, to explore more dataset facets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the DataLad dataset, and place it into the 'data' subdirectory\n",
    "!datalad clone https://github.com/sfb1451/B03_externally-cued-movements.git data\n",
    "# use DataLad to download files matching subject 001 in the 'data' directory\n",
    "!datalad -C data get sub-001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data demos\n",
    "\n",
    "The following steps demo a range of data properties using a single subject's data files (sub-001).\n",
    "\n",
    "The next cell configures the computational environment for the demo code below. The demos use the [MNE](https://mne.tools) software package. All code assumes that it is executed in the `eeg` directory of a particular subject.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d2lEttg4hQ_i"
   },
   "outputs": [],
   "source": [
    "# install MNE\n",
    "!pip install -q mne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAAqcXiTmxfY"
   },
   "source": [
    "### Step 1: Load the EEGLAB file\n",
    "\n",
    "First, load the EEGLAB .set file. This file contains epoched data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start from here after restarting the notebook kernel\n",
    "%matplotlib notebook\n",
    "\n",
    "# enter the data directory\n",
    "%cd data/sub-001/eeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gkXqX5hujfUX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mne\n",
    "from mne.stats import permutation_t_test\n",
    "\n",
    "electrodes = pd.read_csv('sub-001_task-extstim_electrodes.tsv', delimiter='\\t')\n",
    "events = pd.read_csv('sub-001_task-extstim_events.tsv', delimiter='\\t')\n",
    "\n",
    "# Replace 'path_to_your_file.set' with the path to your .set file\n",
    "set_file_path = 'sub-001_task-extstim_eeg.set'\n",
    "epochs = mne.io.read_epochs_eeglab(set_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uM8IgdP9m1AH"
   },
   "source": [
    "### Step 2: Basic Plot of Epochs\n",
    "\n",
    "Start by plotting the epochs to get a basic understanding of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CSoglrz_lvAJ"
   },
   "outputs": [],
   "source": [
    "epochs.plot(n_epochs=10, picks=['eeg'], title='Sample Epochs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDtHyCfXnkov"
   },
   "source": [
    "### Step 3: Plot ERP (Event-Related Potentials) Images\n",
    "\n",
    "ERP images plot the data of each epoch as a single line in an image, which is a good way to visualize condition-specific responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "L6wqhtGqm35Z",
    "outputId": "820287f2-d624-4775-ce36-b67b4202da56"
   },
   "outputs": [],
   "source": [
    "# Specify the event or condition you're interested in\n",
    "event_id = 'S 104'  # Replace with your specific event ID\n",
    "\n",
    "# Plot ERP image for a specific channel\n",
    "epochs[event_id].plot_image(picks=['C3'], sigma=1.0, cmap='viridis')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5N4QOfKbn7eJ"
   },
   "source": [
    "### Step 4: Topographic Maps\n",
    "\n",
    "Topographic maps show the potential field on the scalp, which can be useful to visualize the distribution of brain activity at specific times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dcySPN_gnztZ",
    "outputId": "011377ec-bf54-42ba-ab81-5f6046e66d4f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Time points in seconds (e.g., 250 ms post-stimulus)\n",
    "times = [0.25]\n",
    "epochs[event_id].average().plot_topomap(times=times, ch_type='eeg')\n",
    "\n",
    "# pick EEG Channels\n",
    "picks = mne.pick_types(\n",
    "    epochs.info, meg=False, eeg=True, stim=False, eog=True, exclude=\"bads\"\n",
    ")\n",
    "data = epochs.get_data()\n",
    "times = epochs.times\n",
    "\n",
    "temporal_mask = np.logical_and(0.2 <= times, times <= 0.3)\n",
    "data = np.mean(data[:, :, temporal_mask], axis=2)\n",
    "\n",
    "n_permutations = 50000\n",
    "T0, p_values, H0 = permutation_t_test(data, n_permutations, n_jobs=None)\n",
    "\n",
    "significant_sensors = picks[p_values <= 0.05]\n",
    "significant_sensors_names = [epochs.ch_names[k] for k in significant_sensors]\n",
    "\n",
    "print(\"Number of significant sensors : %d\" % len(significant_sensors))\n",
    "print(\"Sensors names : %s\" % significant_sensors_names)\n",
    "\n",
    "evoked = mne.EvokedArray(-np.log10(p_values)[:, np.newaxis], epochs.info, tmin=0.25)\n",
    "\n",
    "# Extract mask and indices of active sensors in the layout\n",
    "mask = p_values[:, np.newaxis] <= 0.05\n",
    "\n",
    "evoked.plot_topomap(\n",
    "    ch_type=\"eeg\",\n",
    "    times=[0.25],\n",
    "    scalings=1,\n",
    "    time_format=None,\n",
    "    cmap=\"Reds\",\n",
    "    vlim=(0.0, np.max),\n",
    "    units=\"-log10(p)\",\n",
    "    cbar_fmt=\"-%0.1f\",\n",
    "    mask=mask,\n",
    "    size=3,\n",
    "    show_names=lambda x: x[4:] + \" \" * 20,\n",
    "    time_unit=\"s\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFdPvTCMoJOA"
   },
   "source": [
    "### Step 5: Time-Frequency Representation\n",
    "\n",
    "Time-frequency plots can show how the frequency content of the signal changes over time, which is useful for analyzing oscillatory activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "K7sqApeMoBM5",
    "outputId": "4e961269-56b8-4d8e-9fe3-d45b8b03eed1"
   },
   "outputs": [],
   "source": [
    "from mne.time_frequency import tfr_morlet\n",
    "import numpy as np\n",
    "\n",
    "# Choose channels and frequencies\n",
    "channels = ['C4']\n",
    "freqs = np.arange(2, 48)  # 2 to 48 Hz\n",
    "n_cycles = freqs / 2.  # Different number of cycle per frequency\n",
    "\n",
    "power, itc = tfr_morlet(epochs[event_id], freqs=freqs, n_cycles=n_cycles, return_itc=True, picks=channels)\n",
    "\n",
    "# Plotting the time-frequency power\n",
    "power.plot(baseline=(-1.5, -0.5), mode='logratio', title='Time-Frequency Amplitude', vmin=-0.5, vmax=0.5)\n",
    "\n",
    "# Plotting the phase-locking value (ITC) with the color scale from 0 to 1\n",
    "itc.plot(title='Phase-locking', vmin=0, vmax=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3lNCXtXuobP6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
